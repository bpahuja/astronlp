# Results Directory

This directory contains all output files generated by the methodology classification and clustering pipeline.

(Not uploaded as size was a lot, so available in /vol/bitbucket/bp824/astro)

## Structure

```
results/
├── models/           # Trained models and checkpoints
├── embeddings/       # Generated embeddings
├── clusters/         # Clustering results
└── evaluations/      # Evaluation results and metrics
```

## Output Files

### Models (`results/models/`)

- **`bert_classifier.pt`**: Trained BERT classification model
- **`bert_classifier_config.json`**: Model configuration
- **`bert_classifier_tokenizer.json`**: Tokenizer configuration
- **`training_logs.json`**: Training history and metrics

### Embeddings (`results/embeddings/`)

- **`bge-large-en-v1.5.npy`**: BGE embeddings (1024-dim)
- **`e5-large-v2.npy`**: E5 embeddings (1024-dim)
- **`sentence-transformers_all-MiniLM-L6-v2.npy`**: Sentence transformer embeddings (384-dim)
- **`embeddings_metadata.json`**: Embedding generation metadata

### Clusters (`results/clusters/`)

- **`hdbscan/`**: HDBSCAN clustering results
  - `clusters.csv`: Cluster assignments
  - `cluster_profiles.json`: Cluster characteristics
  - `visualization_2d.png`: 2D visualization
  - `visualization_3d.html`: 3D interactive visualization
- **`kmeans/`**: K-means clustering results
  - `clusters.csv`: Cluster assignments
  - `centroids.npy`: Cluster centroids
  - `inertia.json`: Clustering quality metrics

### Evaluations (`results/evaluations/`)

- **`llm/`**: LLM-based evaluation results
  - `cluster_evaluations.json`: GPT-4 cluster assessments
  - `quality_scores.json`: Cluster quality metrics
  - `recommendations.json`: Improvement recommendations
- **`multi_metric/`**: Multi-metric evaluation results
  - `classification_metrics.json`: Classification performance
  - `clustering_metrics.json`: Clustering quality
  - `text_quality_metrics.json`: Text generation quality

## Usage

### Accessing Results

```python
import pandas as pd
import numpy as np
import json

# Load cluster results
clusters = pd.read_csv('results/clusters/hdbscan/clusters.csv')

# Load embeddings
embeddings = np.load('results/embeddings/bge-large-en-v1.5.npy')

# Load evaluation results
with open('results/evaluations/llm/cluster_evaluations.json', 'r') as f:
    evaluations = json.load(f)
```

### Visualizing Results

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Plot cluster distribution
plt.figure(figsize=(10, 6))
sns.countplot(data=clusters, x='cluster_id')
plt.title('Cluster Size Distribution')
plt.show()

# Plot embedding visualization
plt.figure(figsize=(10, 8))
plt.scatter(embeddings[:, 0], embeddings[:, 1], c=clusters['cluster_id'])
plt.title('2D Embedding Visualization')
plt.show()
```

## File Formats

### CSV Files

```csv
paper_id,cluster_id,confidence,methodology_type
astro-ph/1234567,0,0.95,observational
astro-ph/1234568,1,0.87,theoretical
astro-ph/1234569,0,0.92,observational
```

### JSON Files

```json
{
  "cluster_id": 0,
  "size": 150,
  "methodology_type": "observational",
  "representative_papers": ["astro-ph/1234567", "astro-ph/1234568"],
  "keywords": ["photometry", "spectroscopy", "imaging"],
  "quality_score": 8.5
}
```

### NumPy Files

```python
# Embeddings: (num_samples, embedding_dim)
embeddings = np.load('results/embeddings/bge-large-en-v1.5.npy')
print(embeddings.shape)  # (10000, 1024)

# Centroids: (num_clusters, embedding_dim)
centroids = np.load('results/clusters/kmeans/centroids.npy')
print(centroids.shape)  # (50, 1024)
```

## Dependencies

- `pandas`: CSV file handling
- `numpy`: NumPy file handling
- `json`: JSON file handling
- `matplotlib`: Visualization
- `seaborn`: Statistical visualization
- `plotly`: Interactive visualization

## Related Documentation

- [Main README](../README.md)
- [Pipeline Documentation](../)
- [Evaluation Pipeline](../06_evaluation/README.md)
